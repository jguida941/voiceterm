# Whisper Speech-to-Text

VoiceTerm uses [Whisper](https://github.com/openai/whisper) for local speech-to-text.
All transcription happens on your machine. No audio is sent to the cloud.

Docs map:

- User guides index: [README.md](README.md)
- Quick start: [../QUICK_START.md](../QUICK_START.md)
- Engineering history: [../dev/history/ENGINEERING_EVOLUTION.md](../dev/history/ENGINEERING_EVOLUTION.md)

## Contents

- [How It Works](#how-it-works)
- [Choosing a Model](#choosing-a-model)
- [Language Support](#language-support)
- [Model Download](#model-download)
- [Performance Tips](#performance-tips)

## How It Works

1. **You speak** → VoiceTerm captures audio from your microphone
2. **Voice Activity Detection (VAD)** → Detects when you start/stop speaking
3. **Whisper transcribes** → Converts speech to text locally
4. **Text typed into CLI** → Transcript is injected into your AI CLI terminal

The entire pipeline runs locally.
Latency depends on model size, clip length, and hardware.

## Choosing a Model

| Model | Size | Speed | Accuracy | Best For |
|-------|------|-------|----------|----------|
| `tiny` | 75 MB | Fastest | Lower | Quick testing, low-end hardware |
| `base` | 142 MB | Fast | Good | **Recommended for most users** |
| `small` | 466 MB | Medium | Better | Default, good balance |
| `medium` | 1.5 GB | Slower | High | Non-English languages |
| `large` | 3.1 GB | Slowest | Highest | Maximum accuracy needed |

### Recommendations

- **Start with `base`** - good accuracy, fast, small download
- **Use `small`** if you want better accuracy
- **Use `medium` or `large`** for non-English languages or harder accents
- **Use `tiny`** for testing or very low-end hardware

**Note:** `--whisper-model` defaults to `small`. Installer/start scripts
download `base` by default unless you choose another size. VoiceTerm
auto-detects whichever model file is present.

### Switching Models

Download a different model:

```bash
./scripts/setup.sh models --base    # 142 MB, recommended
./scripts/setup.sh models --small   # 466 MB, default
./scripts/setup.sh models --medium  # 1.5 GB
./scripts/setup.sh models --tiny    # 75 MB, fastest
```

Or specify at runtime:

```bash
voiceterm --whisper-model base
voiceterm --whisper-model-path /path/to/ggml-medium.en.bin
```

## Language Support

Whisper supports many languages. VoiceTerm defaults to English.

<details>
<summary><strong>Language setup details</strong></summary>

### Setting Your Language

```bash
# Explicit language (faster, more accurate)
voiceterm --lang es        # Spanish
voiceterm --lang fr        # French
voiceterm --lang de        # German
voiceterm --lang ja        # Japanese
voiceterm --lang zh        # Chinese

# Auto-detect (slightly slower)
voiceterm --lang auto
```

### Language-Specific Models

Models ending in `.en` are English-only and a bit faster/smaller:

- `ggml-base.en.bin` - English only
- `ggml-base.bin` - Multilingual

For non-English languages, use multilingual models (without `.en`).
The setup script downloads English `.en` models by default, so download a
multilingual file manually:

```bash
curl -L https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-base.bin \
  -o whisper_models/ggml-base.bin

voiceterm --whisper-model-path whisper_models/ggml-base.bin --lang es
```

### Tested Languages

| Language | Status | Notes |
|----------|--------|-------|
| English | Tested | Works great with `.en` models |
| Others | Should work | Use multilingual models, `--lang <code>` |

Full language list:
[Whisper supported languages](https://github.com/openai/whisper#available-models-and-languages)

</details>

## Model Download

Models are downloaded automatically on first run. Manual download:

```bash
# Using setup script (recommended)
./scripts/setup.sh models --base

# Direct download
curl -L https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-base.en.bin \
  -o whisper_models/ggml-base.en.bin
```

### Model Locations

VoiceTerm looks for models in this order:

1. Path specified via `--whisper-model-path`
2. `whisper_models/` in the project directory

Install/start scripts also check `~/.local/share/voiceterm/models/` and pass it
via `--whisper-model-path` when found.

Override with environment variable (used by install/start scripts):

```bash
export VOICETERM_MODEL_DIR=/path/to/models
```

## Performance Tips

### Reduce Latency

1. **Use a smaller model** - `base` is much faster than `small`
2. **Speak in shorter phrases** - transcription time scales with audio length
3. **Use English-only models** - `.en` models are a little faster
4. **Set explicit language** - avoids auto-detect overhead

### Improve Accuracy

1. **Use a larger model** - `small` or `medium` gives better results
2. **Speak clearly** - pause between sentences
3. **Reduce background noise** - adjust mic sensitivity with `Ctrl+]` / `Ctrl+\`
4. **Set the correct language** - do not rely on auto-detect

<details>
<summary><strong>Troubleshooting and advanced tuning</strong></summary>

### Troubleshooting

**Transcription is slow:**

- Switch to a smaller model (`--whisper-model base`)
- Check CPU usage - Whisper is CPU-intensive

**Wrong language detected:**

- Set language explicitly (`--lang en`)
- Use language-specific model (`.en` for English)

**Poor accuracy:**

- Try a larger model (`--whisper-model medium`)
- Adjust mic sensitivity
- Speak closer to the microphone

### Advanced tuning

Whisper options (native pipeline):

- `--whisper-beam-size <N>`: beam search size (0 = fastest, greedy decoding)
- `--whisper-temperature <T>`: transcription randomness (0.0 = most predictable)

Fallback control:

- `--no-python-fallback`: fail instead of using the Python pipeline

</details>

## See Also

| Topic | Link |
|-------|------|
| Guides index | [README.md](README.md) |
| Usage guide | [USAGE.md](USAGE.md) |
| Install guide | [INSTALL.md](INSTALL.md) |
| CLI Flags | [CLI_FLAGS.md](CLI_FLAGS.md) |
| Troubleshooting | [TROUBLESHOOTING.md](TROUBLESHOOTING.md) |
| Quick Start | [QUICK_START.md](../QUICK_START.md) |
